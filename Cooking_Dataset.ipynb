{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "with open('train/cooking_data.json') as data_file:\n",
    "    data_train = pd.read_json(data_file)\n",
    "#print (data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "#data_train['process_ingredients'] = [' , '.join(z).strip() for z in data_train['ingredients']]\n",
    "data_train['process_ingredients'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in data_train['ingredients']] \n",
    "#data_train = data_train.drop(columns=['process_ingredients'])\n",
    "#pprint(data_train.head())\n",
    "#pprint(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(columns=['ingredients'])\n",
    "#pprint(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " data_train = data_train.rename(index=str, columns={\"process_ingredients\": \"ingredients\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cuisine     id                                        ingredients\n",
      "0        greek  10259  romaine lettuce black olives grape tomatoes ga...\n",
      "1  southern_us  25693  plain flour ground pepper salt tomato ground b...\n",
      "2     filipino  20130  egg pepper salt mayonaise cooking oil green ch...\n",
      "3       indian  22213                     water vegetable oil wheat salt\n",
      "4       indian  13162  black pepper shallot cornflour cayenne pepper ...\n"
     ]
    }
   ],
   "source": [
    "pprint (data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "corpus = []\n",
    "total = 39774\n",
    "for i in range(0, 39774):\n",
    "    item = re.sub('[^a-zA-Z]',' ',data_train['ingredients'][i])\n",
    "    item = item.lower()\n",
    "    item = item.split()\n",
    "   # print(item)\n",
    "    #ps = PorterStemmer()\n",
    "    \n",
    "    item = [ps.stem(word) for word in item]\n",
    "    item = ' '.join(item)\n",
    "    #print (item)\n",
    "    corpus.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape - (39774, 2625)\n",
      "y- {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "y- 39774\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cv = CountVectorizer()\n",
    "tf = TfidfTransformer()\n",
    "#X = cv.fit_transform(corpus).toarray()\n",
    "X = cv.fit_transform(corpus)\n",
    "X = tf.fit_transform(X)\n",
    "\n",
    "print (\"X shape -\", X.shape)\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(data_train['cuisine'])\n",
    "print (\"y-\", set(y))\n",
    "print (\"y-\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy CV: [0.66917765 0.65682425 0.6623193  0.65057399 0.65958786]\n",
      "[22  0  3  1  0  3  0  5  0 20  0  0  0 20  0  0 30  1  2  0]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Validation set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Fitting Multinomial Naive Bayes Model to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print('accuracy CV:',scores)\n",
    "\n",
    "#Predicting for validation set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (cm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22  0  3  1  0  3  0  5  0 20  0  0  0 20  0  0 30  1  2  0]\n",
      "[ 0  9  1  0  0 33  0  6  1 28  1  0  0  4  0  0 83  0  0  0]\n",
      "[  0   0 151   0   0   4   0   3   1  33   0   0   0  21   0   0  57   0\n",
      "   0   0]\n",
      "[  0   0   0 519   0   3   0   3   0   4   0   2   0   7   1   0  13   0\n",
      "   6   3]\n",
      "[ 0  0  0 57 10  0  0  7  0 17  0  0  0  8  0  0 26  0 15  0]\n",
      "[  0   3   1   2   0 218   0   3   0 190   0   1   0   6   0   0  98   0\n",
      "   0   1]\n",
      "[  0   0   0   0   0   9  72  13   0 127   0   0   0  13   0   0  12   0\n",
      "   0   0]\n",
      "[  0   0   1   4   0   0   1 590   0  10   0   0   0  14   1   0  13   0\n",
      "   2   1]\n",
      "[ 0  0  0  2  0 16  0  1  8 24  0  0  0  3  0  0 67  0  0  0]\n",
      "[   0    0    1    0    0   57    2    2    0 1389    0    0    0   25\n",
      "    1    1   72    0    1    0]\n",
      "[ 0  1  5  7  0  3  0  8  0 15 13  0  0 20  0  0 49  0  1  0]\n",
      "[  0   0   1  67   0   4   0  18   0  11   0 149   2   2   0   0  21   0\n",
      "   0   0]\n",
      "[ 0  0  0 82  0  0  0  0  0  2  0  9 45  2  0  0  3  0  2  0]\n",
      "[   0    0    0    4    0    5    0    6    0   27    0    0    0 1226\n",
      "    0    0   48    0    1    0]\n",
      "[ 0  0  0  0  0  3  0 47  0 28  0  0  0 16 57  0  9  1  0  0]\n",
      "[ 0  1  0  0  0 18  1  3  0 15  0  0  0 11  0  2 41  0  0  0]\n",
      "[  0   1  32  11   0   8   0  11   1  85   0   1   0  45   0   0 655   0\n",
      "   1   1]\n",
      "[  0   0   4   1   0  15   1   3   0 104   0   0   0  23   0   0  16  31\n",
      "   1   0]\n",
      "[  0   0   0  36   0   0   0  17   0   2   0   1   0   8   0   0   4   0\n",
      " 237   1]\n",
      "[ 0  0  0 46  1  0  0  2  0  2  0  1  0  6  0  0  5  0 79 22]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(0,np.size(cm,0)):\n",
    "    print (cm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "recall = cm[1][1]/ (cm[1][1] + cm[1][0])\n",
    "f1_score = (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8290598290598291\n"
     ]
    }
   ],
   "source": [
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 107\n",
      "Class -  0 Accuracy -  0.205607476635514\n",
      "9 166\n",
      "Class -  1 Accuracy -  0.05421686746987952\n",
      "151 270\n",
      "Class -  2 Accuracy -  0.5592592592592592\n",
      "519 561\n",
      "Class -  3 Accuracy -  0.9251336898395722\n",
      "10 140\n",
      "Class -  4 Accuracy -  0.07142857142857142\n",
      "218 523\n",
      "Class -  5 Accuracy -  0.4168260038240918\n",
      "72 246\n",
      "Class -  6 Accuracy -  0.2926829268292683\n",
      "590 637\n",
      "Class -  7 Accuracy -  0.9262166405023547\n",
      "8 121\n",
      "Class -  8 Accuracy -  0.06611570247933884\n",
      "1389 1551\n",
      "Class -  9 Accuracy -  0.8955512572533849\n",
      "13 122\n",
      "Class -  10 Accuracy -  0.10655737704918032\n",
      "149 275\n",
      "Class -  11 Accuracy -  0.5418181818181819\n",
      "45 145\n",
      "Class -  12 Accuracy -  0.3103448275862069\n",
      "1226 1317\n",
      "Class -  13 Accuracy -  0.9309035687167806\n",
      "57 161\n",
      "Class -  14 Accuracy -  0.35403726708074534\n",
      "2 92\n",
      "Class -  15 Accuracy -  0.021739130434782608\n",
      "655 852\n",
      "Class -  16 Accuracy -  0.7687793427230047\n",
      "31 199\n",
      "Class -  17 Accuracy -  0.15577889447236182\n",
      "237 306\n",
      "Class -  18 Accuracy -  0.7745098039215687\n",
      "22 164\n",
      "Class -  19 Accuracy -  0.13414634146341464\n",
      "Avg. Accuracy -  0.6819610307982401\n"
     ]
    }
   ],
   "source": [
    "sum_ = 0\n",
    "diagonal = 0\n",
    "for i in range(0,np.size(cm,0)):\n",
    "    print (cm[i][i], sum(cm[i]))\n",
    "    diagonal = diagonal + cm[i][i] \n",
    "    sum_ = sum_ + sum(cm[i])\n",
    "    print (\"Class - \", i, \"Accuracy - \", cm[i][i]/sum(cm[i]))\n",
    "print (\"Avg. Accuracy - \", diagonal/sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
